combinario â€“ merge two words and let AI create a brand-new concept.

Project is work in progress.

This is an attempt of making an open source implementation of Infinite Craft by Neal Agarwal at:
    https://neal.fun/infinite-craft/

Run via Docker:
    docker compose up

Stack:
    Runs on llama.cpp server, FastAPI for backend, arq for task queries, SQLAlchemy for ORM queries (to postgres) and pydantic for data validation.

LLM notes:
    The recommended model for local generation is Meta Llama 3.1 8B Instruct Q6_K.
    Models can be downloaded from Hugging Face.
    If you want to use another server instead of llama.cpp (e.g. ollama), edit the ./dockerfile
    Any server is fine if as long as it has OpenAI Chat completions API support.
    VLLM is not recommended, as it does not support quantized models, but the choice shall rather be made depending on hardware limitations.